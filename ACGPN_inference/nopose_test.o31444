
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


?
------------ Options -------------
batchSize: 1
beta1: 0.5
checkpoints_dir: ../ACGPN_train/checkpoints/
clothlmg2: False
clothrep: False
continue_train: False
data_type: 32
dataroot: ../../test_data/
debug: False
dense: False
densearms: False
denseone: False
denseplus: True
densestack: False
display_freq: 100
display_winsize: 512
fineSize: 512
gpu_ids: [0]
input_nc: 3
isTrain: True
label_nc: 20
lambda_feat: 10.0
landmarks: True
loadSize: 512
load_pretrain: ./checkpoints/label2city
lr: 0.0002
max_dataset_size: inf
mesh: False
mesh_g: False
model: pix2pixHD
nThreads: 2
n_blocks_global: 4
n_blocks_local: 3
n_downsample_global: 4
n_layers_D: 3
n_local_enhancers: 1
name: denseplus_flm_nobodyseg_nopose
ndf: 64
neck: False
netG: global
ngf: 64
niter: 100
niter_decay: 100
niter_fix_global: 0
no_flip: False
no_ganFeat_loss: False
no_html: False
no_lsgan: False
no_vgg_loss: False
nobodyseg: True
nocollar: False
noopenpose: True
norm: instance
num_D: 2
output_nc: 3
pants: False
phase: test
pool_size: 0
print_freq: 100
resize_or_crop: scale_width
save_epoch_freq: 10
save_latest_freq: 1000
serial_batches: False
tf_log: False
transfer: False
use_dropout: False
verbose: False
which_epoch: latest
-------------- End ----------------
CustomDatasetDataLoader
dataset [AlignedDataset] was created
../../test_data/test_label label
../../test_data/test_label label
../../test_data/test_img img
../../test_data/test_img img
../../test_data/test_edge edge
../../test_data/test_edge edge
../../test_data/test_mask mask
../../test_data/test_mask mask
../../test_data/test_colormask colormask
../../test_data/test_colormask colormask
../../test_data/test_color color
../../test_data/test_color color
../../test_data/test_seg seg
../../test_data/test_seg seg
../../test_data/test_mesh mesh
../../test_data/test_mesh mesh
../../test_data/test_dense dense
../../test_data/test_dense dense
../../test_data/test_landmarks_cloth cloth
../../test_data/test_landmarks_cloth cloth
# Inference images = 2032
latest_net_U.pth
latest_net_G1.pth
latest_net_G2.pth
latest_net_G.pth
/home/gcrepaldi/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  warnings.warn("The use of the transforms.Scale transform is deprecated, " +
/home/gcrepaldi/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  warnings.warn("The use of the transforms.Scale transform is deprecated, " +
/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
Traceback (most recent call last):
  File "test.py", line 285, in <module>
    Variable(mask_fore.cuda()))
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/work/gcrepaldi/vton/acgpn_custom/ACGPN_inference/models/pix2pixHD_model.py", line 356, in forward
    fake_cl = self.G2.refine(G2_in)
  File "/work/gcrepaldi/vton/acgpn_custom/ACGPN_inference/models/networks.py", line 739, in refine
    conv1 = self.conv1(input)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 423, in forward
    return self._conv_forward(input, self.weight)
  File "/home/gcrepaldi/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 420, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 22, 3, 3], expected input[1, 28, 256, 192] to have 22 channels, but got 28 channels instead
